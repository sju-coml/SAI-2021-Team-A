{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-NET.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adZQlWIqPaGw"
      },
      "source": [
        "## UNET SEGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zz2ulcgOh4N"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy import misc\n",
        "import numpy as np\n",
        "from torchvision.transforms import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfhZ5uwWPeQZ"
      },
      "source": [
        "save_dir = './drive/MyDrive/Colab Notebooks/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhSxY0TOSpOh"
      },
      "source": [
        "img_dir = os.path.join(save_dir, 'train', 'image')\n",
        "lab_dir = os.path.join(save_dir, 'train', 'label')\n",
        "img_fns = os.listdir(img_dir)\n",
        "f, axarr = plt.subplots(3, 8, figsize=(40, 15))\n",
        "indexs = random.sample(range(len(img_fns)), 12)\n",
        "\n",
        "for (i, index) in enumerate(indexs):\n",
        "    img_fn = img_fns[index]\n",
        "    lab_fn = img_fn\n",
        "    img_path = os.path.join(img_dir, img_fn)\n",
        "    label_path = os.path.join(lab_dir, lab_fn)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)[np.newaxis, :][0]\n",
        "    label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)[np.newaxis, :][0]\n",
        "    axarr[i*2//8][i*2%8].axis('off')\n",
        "    axarr[i*2//8][i*2%8].set_title(img_fn)\n",
        "    axarr[i*2//8][i*2%8].imshow(img)\n",
        "    axarr[(i*2+1)//8][(i*2+1)%8].axis('off')\n",
        "    axarr[(i*2+1)//8][(i*2+1)%8].set_title(lab_fn)\n",
        "    axarr[(i*2+1)//8][(i*2+1)%8].imshow(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOOxtHaAQbC1"
      },
      "source": [
        "## u-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tncqkyz7PgGW"
      },
      "source": [
        "def conv3x3(in_channels, out_channels, stride=1, padding=1, activate='relu'):\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding))\n",
        "    layers.append(nn.BatchNorm2d(out_channels))\n",
        "    if activate == 'relu':\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "    elif activate == 'sigmoid':\n",
        "        layers.append(nn.Sigmoid())\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHzB0MltRicO"
      },
      "source": [
        "def double_conv3x3(in_channels, out_channels, stride=1, padding=1, activate='relu'):\n",
        "    return nn.Sequential(\n",
        "        conv3x3(in_channels, out_channels, stride, padding=1, activate=activate),\n",
        "        conv3x3(out_channels, out_channels, stride, padding=1, activate=activate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KU4t-pSPjta"
      },
      "source": [
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            double_conv3x3(in_channels, out_channels))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KbjebzLPlw9"
      },
      "source": [
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.bilinear = bilinear\n",
        "        self.conv_trans = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)\n",
        "        self.net = double_conv3x3(in_channels, out_channels)\n",
        "        \n",
        "    def forward(self, front, later):\n",
        "        if self.bilinear:\n",
        "            later = F.interpolate(later, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            later = self.conv_trans(later)\n",
        "        h_diff = front.size()[2] - later.size()[2]\n",
        "        w_diff = front.size()[3] - later.size()[3]\n",
        "        later = F.pad(later, pad=(w_diff//2,w_diff-w_diff//2,h_diff//2,h_diff-h_diff//2), mode='constant',value=0)\n",
        "        x = torch.cat([front, later], dim=1)\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VE4HrC9TYxg"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inconv = double_conv3x3(1, 64)\n",
        "        self.down1 = DownSample(64, 128)\n",
        "        self.down2 = DownSample(128, 256)\n",
        "        self.down3 = DownSample(256, 512)\n",
        "        self.down4 = DownSample(512, 512)\n",
        "        self.up1 = UpSample(1024, 256)\n",
        "        self.up2 = UpSample(512, 128)\n",
        "        self.up3 = UpSample(256, 64)\n",
        "        self.up4 = UpSample(128, 64)\n",
        "        self.outconv = double_conv3x3(64, 1, activate='sigmoid')\n",
        "        \n",
        "        self._init_weights()\n",
        "        \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "                \n",
        "    def forward(self, x):\n",
        "        x1 = self.inconv(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "        x = self.up1(x4, x5)\n",
        "        x = self.up2(x3, x)\n",
        "        x = self.up3(x2, x)\n",
        "        x = self.up4(x1, x)\n",
        "        x = self.outconv(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZEICqmQQmSK"
      },
      "source": [
        "## data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr96wdTWPoMn"
      },
      "source": [
        "import torch.utils.data as data\n",
        "from torch.utils.data.dataset import Dataset \n",
        "class Loader(Dataset):\n",
        "    def __init__(self, split, save_dir):\n",
        "        image_dir = os.path.join(save_dir, split, 'image')\n",
        "        label_dir = os.path.join(save_dir, split, 'label')\n",
        "        self.images, self.labels = self._read_data(image_dir, label_dir)\n",
        "        self.trans = Compose([\n",
        "            ToPILImage(),\n",
        "            RandomHorizontalFlip(0.5),\n",
        "            RandomVerticalFlip(0.5),\n",
        "            RandomResizedCrop(572),\n",
        "            ToTensor()])\n",
        "\n",
        "    def _read_data(self, image_dir, label_dir):\n",
        "        images, labels = [], []\n",
        "        img_fns = os.listdir(image_dir)\n",
        "        for img_fn in img_fns:\n",
        "            image_path = os.path.join(image_dir, img_fn)\n",
        "            label_path = os.path.join(label_dir, img_fn)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) / 255.\n",
        "            images.append(image[np.newaxis,:])\n",
        "            label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE) / 255.\n",
        "            label[label > 0.5] = 1\n",
        "            label[label <= 0.5] = 0\n",
        "            labels.append(label[np.newaxis,:])\n",
        "        return images, labels\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        if np.random.uniform(0, 1) < 0.5:\n",
        "            image = image[:, ::-1, :]\n",
        "            label = label[:, ::-1, :]\n",
        "        if np.random.uniform(0, 1) < 0.5:\n",
        "            image = image[:, :, ::-1]\n",
        "            label = label[:, :, ::-1]\n",
        "        \n",
        "        image = np.ascontiguousarray(image)\n",
        "        label = np.ascontiguousarray(label)\n",
        "        image = torch.from_numpy(image).float()\n",
        "        label = torch.from_numpy(label).float()\n",
        "        \n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66DgEIj6Qr1d"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAYco_rjPqrM"
      },
      "source": [
        "import torch.nn.functional as F \n",
        "def accuracy(logit, target, threshold=0.5):\n",
        "    logit[logit > threshold] = 1\n",
        "    logit[logit <= threshold] = 0\n",
        "    return (logit.long() == target.long()).float().mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCah5MDpQvA4"
      },
      "source": [
        "def adjust_lr(optimizer, lr_gamma=0.1):\n",
        "    for (i, param_group) in enumerate(optimizer.param_groups):\n",
        "        param_group['lr'] = param_group['lr'] * lr_gamma\n",
        "    return optimizer.state_dict()['param_groups'][0]['lr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XpQ_w_2Qwvj"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwmYuxyAQ4_Y"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "def step(split, epoch, model, criterion, optimizer, batch_size=1, cuda=False):\n",
        "    \n",
        "    if split == 'train':\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    loader = data.DataLoader(Loader(split, save_dir), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    epoch_loss, epoch_acc, n_batchs = 0, 0, 0\n",
        "    for i, (image, label) in enumerate(loader):\n",
        "        n_batchs += image.size(0)\n",
        "        if cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "        logit = model(image)\n",
        "        logit = logit.flatten()\n",
        "        label = label.flatten()\n",
        "        loss = criterion(logit, label)\n",
        "        if split == 'train':\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += accuracy(logit, label) * 100\n",
        "    epoch_loss /= n_batchs\n",
        "    epoch_acc /= n_batchs\n",
        "    return epoch_loss, epoch_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOboUKqfQ5wC"
      },
      "source": [
        "batch_size = 1\n",
        "pretrained = False\n",
        "cuda = True\n",
        "start_epoch = 1\n",
        "end_epoch = 60\n",
        "lr_decay = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfFTlvNxQ8mn"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = UNet()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.99, weight_decay=0.0005)\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "if pretrained:\n",
        "    model.load_state_dict(torch.load('model.pth'))\n",
        "train_losses, val_losses = [], []\n",
        "for epoch in range(start_epoch, end_epoch):\n",
        "    if epoch % lr_decay == 0:\n",
        "        lr = adjust_lr(optimizer)\n",
        "        print('adjust LR to {:.4f}'.format(lr))\n",
        "    tepoch_loss, tepoch_acc = step('train', epoch, model, criterion, optimizer, batch_size, cuda=cuda)\n",
        "    vepoch_loss, vepoch_acc = step('val', epoch, model, criterion, optimizer, batch_size, cuda=cuda)\n",
        "    train_losses.append(tepoch_loss)\n",
        "    val_losses.append(vepoch_loss)\n",
        "    print('epoch {0:} finished, tloss:{1:.4f} [{2:.2f}%]  vloss:{3:.4f} [{4:.2f}%]'.format(epoch, tepoch_loss, tepoch_acc, vepoch_loss, vepoch_acc))\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "print('done!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJCrILdTT6ml"
      },
      "source": [
        "\n",
        "## visualize output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzArwx8nT4kS"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(train_losses)+1), train_losses, c='blue', label='train')\n",
        "plt.plot(range(1, len(val_losses)+1), val_losses, c='red', label='val')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epNh7DcZT-MQ"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pth'))\n",
        "loader = data.DataLoader(Loader('val', save_dir), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "for (img, lab) in loader:\n",
        "    if cuda:\n",
        "        img = img.cuda()\n",
        "        lab = lab.cuda()\n",
        "    out = model(img)\n",
        "    print('Loss: {:.4f} [{:.2f}%]'.format(criterion(out, lab).item(), accuracy(out, lab) * 100.))\n",
        "    out = torch.sigmoid(out)\n",
        "    out[out > 0.5] = 1\n",
        "    out[out <= 0.5] = 0\n",
        "    out = out.detach().cpu().numpy()[0, 0] * 255.\n",
        "    show_img = img.cpu().numpy()[0, 0]\n",
        "    show_lab = lab.cpu().numpy()[0, 0] * 255.\n",
        "    f, axarr = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axarr[0].imshow(show_img)\n",
        "    axarr[1].imshow(show_lab)\n",
        "    axarr[2].imshow(out)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}