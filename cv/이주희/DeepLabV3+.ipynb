{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabV3+.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmA0kQzuSBla",
        "outputId": "1115e0fe-2a5c-4bec-c633-b976a9a55d31"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\" Deeplabv3+ model for Keras.\n",
        "This model is based on TF repo:\n",
        "https://github.com/tensorflow/models/tree/master/research/deeplab\n",
        "On Pascal VOC, original model gets to 84.56% mIOU\n",
        "This model is only available for the TensorFlow backend,\n",
        "due to its reliance on `SeparableConvolution` layers.\n",
        "# Reference\n",
        "- [Encoder-Decoder with Atrous Separable Convolution\n",
        "    for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Softmax\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import DepthwiseConv2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.engine import Layer\n",
        "from keras.engine import InputSpec\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras import backend as K\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.utils import conv_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "TF_WEIGHTS_PATH = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.0/deeplabv3_weights_tf_dim_ordering_tf_kernels.h5\"\n",
        "\n",
        "\n",
        "class BilinearUpsampling(Layer):\n",
        "    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n",
        "       Args:\n",
        "           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n",
        "           output_size: used instead of upsampling arg if passed!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n",
        "\n",
        "        super(BilinearUpsampling, self).__init__(**kwargs)\n",
        "\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "        if output_size:\n",
        "            self.upsample_size = conv_utils.normalize_tuple(\n",
        "                output_size, 2, 'size')\n",
        "            self.upsampling = None\n",
        "        else:\n",
        "            self.upsampling = conv_utils.normalize_tuple(upsampling, 2, 'size')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.upsampling:\n",
        "            height = self.upsampling[0] * \\\n",
        "                input_shape[1] if input_shape[1] is not None else None\n",
        "            width = self.upsampling[1] * \\\n",
        "                input_shape[2] if input_shape[2] is not None else None\n",
        "        else:\n",
        "            height = self.upsample_size[0]\n",
        "            width = self.upsample_size[1]\n",
        "        return (input_shape[0],\n",
        "                height,\n",
        "                width,\n",
        "                input_shape[3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.upsampling:\n",
        "            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\n",
        "                                                       inputs.shape[2] * self.upsampling[1]),\n",
        "                                              align_corners=True)\n",
        "        else:\n",
        "            return K.tf.image.resize_bilinear(inputs, (self.upsample_size[0],\n",
        "                                                       self.upsample_size[1]),\n",
        "                                              align_corners=True)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'size': self.upsampling,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(BilinearUpsampling, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
        "    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n",
        "        Implements right \"same\" padding for even kernel sizes\n",
        "        Args:\n",
        "            x: input tensor\n",
        "            filters: num of filters in pointwise convolution\n",
        "            prefix: prefix before name\n",
        "            stride: stride at depthwise conv\n",
        "            kernel_size: kernel size for depthwise convolution\n",
        "            rate: atrous rate for depthwise convolution\n",
        "            depth_activation: flag to use activation between depthwise & poinwise convs\n",
        "            epsilon: epsilon to use in BN layer\n",
        "    \"\"\"\n",
        "\n",
        "    if stride == 1:\n",
        "        depth_padding = 'same'\n",
        "    else:\n",
        "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
        "        pad_total = kernel_size_effective - 1\n",
        "        pad_beg = pad_total // 2\n",
        "        pad_end = pad_total - pad_beg\n",
        "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
        "        depth_padding = 'valid'\n",
        "\n",
        "    if not depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
        "                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n",
        "    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n",
        "    if depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same',\n",
        "               use_bias=False, name=prefix + '_pointwise')(x)\n",
        "    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n",
        "    if depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n",
        "    \"\"\"Implements right 'same' padding for even kernel sizes\n",
        "        Without this there is a 1 pixel drift when stride = 2\n",
        "        Args:\n",
        "            x: input tensor\n",
        "            filters: num of filters in pointwise convolution\n",
        "            prefix: prefix before name\n",
        "            stride: stride at depthwise conv\n",
        "            kernel_size: kernel size for depthwise convolution\n",
        "            rate: atrous rate for depthwise convolution\n",
        "    \"\"\"\n",
        "    if stride == 1:\n",
        "        return Conv2D(filters,\n",
        "                      (kernel_size, kernel_size),\n",
        "                      strides=(stride, stride),\n",
        "                      padding='same', use_bias=False,\n",
        "                      dilation_rate=(rate, rate),\n",
        "                      name=prefix)(x)\n",
        "    else:\n",
        "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
        "        pad_total = kernel_size_effective - 1\n",
        "        pad_beg = pad_total // 2\n",
        "        pad_end = pad_total - pad_beg\n",
        "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
        "        return Conv2D(filters,\n",
        "                      (kernel_size, kernel_size),\n",
        "                      strides=(stride, stride),\n",
        "                      padding='valid', use_bias=False,\n",
        "                      dilation_rate=(rate, rate),\n",
        "                      name=prefix)(x)\n",
        "\n",
        "\n",
        "def xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n",
        "                   rate=1, depth_activation=False, return_skip=False):\n",
        "    \"\"\" Basic building block of modified Xception network\n",
        "        Args:\n",
        "            inputs: input tensor\n",
        "            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n",
        "            prefix: prefix before name\n",
        "            skip_connection_type: one of {'conv','sum','none'}\n",
        "            stride: stride at last depthwise conv\n",
        "            rate: atrous rate for depthwise convolution\n",
        "            depth_activation: flag to use activation between depthwise & pointwise convs\n",
        "            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n",
        "            \"\"\"\n",
        "    residual = inputs\n",
        "    for i in range(3):\n",
        "        residual = SepConv_BN(residual,\n",
        "                              depth_list[i],\n",
        "                              prefix + '_separable_conv{}'.format(i + 1),\n",
        "                              stride=stride if i == 2 else 1,\n",
        "                              rate=rate,\n",
        "                              depth_activation=depth_activation)\n",
        "        if i == 1:\n",
        "            skip = residual\n",
        "    if skip_connection_type == 'conv':\n",
        "        shortcut = conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n",
        "                               kernel_size=1,\n",
        "                               stride=stride)\n",
        "        shortcut = BatchNormalization(name=prefix + '_shortcut_BN')(shortcut)\n",
        "        outputs = layers.add([residual, shortcut])\n",
        "    elif skip_connection_type == 'sum':\n",
        "        outputs = layers.add([residual, inputs])\n",
        "    elif skip_connection_type == 'none':\n",
        "        outputs = residual\n",
        "    if return_skip:\n",
        "        return outputs, skip\n",
        "    else:\n",
        "        return outputs\n",
        "\n",
        "\n",
        "def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, OS=16):\n",
        "    \"\"\" Instantiates the Deeplabv3+ architecture\n",
        "    Optionally loads weights pre-trained\n",
        "    on PASCAL VOC. This model is available for TensorFlow only,\n",
        "    and can only be used with inputs following the TensorFlow\n",
        "    data format `(width, height, channels)`.\n",
        "    # Arguments\n",
        "        weights: one of 'pascal_voc' (pre-trained on pascal voc)\n",
        "            or None (random initialization)\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: shape of input image. format HxWxC\n",
        "            PASCAL VOC model was trained on (512,512,3) images\n",
        "        classes: number of desired classes. If classes != 21,\n",
        "            last layer is initialized randomly\n",
        "        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        RuntimeError: If attempting to run this model with a\n",
        "            backend that does not support separable convolutions.\n",
        "        ValueError: in case of invalid argument for `weights`\n",
        "    \"\"\"\n",
        "\n",
        "    if not (weights in {'pascal_voc', None}):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `pascal_voc` '\n",
        "                         '(pre-trained on PASCAL VOC)')\n",
        "\n",
        "    if K.backend() != 'tensorflow':\n",
        "        raise RuntimeError('The Deeplabv3+ model is only available with '\n",
        "                           'the TensorFlow backend.')\n",
        "\n",
        "    if OS == 8:\n",
        "        entry_block3_stride = 1\n",
        "        middle_block_rate = 2  # ! Not mentioned in paper, but required\n",
        "        exit_block_rates = (2, 4)\n",
        "        atrous_rates = (12, 24, 36)\n",
        "    else:\n",
        "        entry_block3_stride = 2\n",
        "        middle_block_rate = 1\n",
        "        exit_block_rates = (1, 2)\n",
        "        atrous_rates = (6, 12, 18)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2),\n",
        "               name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n",
        "    x = BatchNormalization(name='entry_flow_conv1_1_BN')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n",
        "    x = BatchNormalization(name='entry_flow_conv1_2_BN')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = xception_block(x, [128, 128, 128], 'entry_flow_block1',\n",
        "                       skip_connection_type='conv', stride=2,\n",
        "                       depth_activation=False)\n",
        "    x, skip1 = xception_block(x, [256, 256, 256], 'entry_flow_block2',\n",
        "                              skip_connection_type='conv', stride=2,\n",
        "                              depth_activation=False, return_skip=True)\n",
        "\n",
        "    x = xception_block(x, [728, 728, 728], 'entry_flow_block3',\n",
        "                       skip_connection_type='conv', stride=entry_block3_stride,\n",
        "                       depth_activation=False)\n",
        "    for i in range(16):\n",
        "        x = xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n",
        "                           skip_connection_type='sum', stride=1, rate=middle_block_rate,\n",
        "                           depth_activation=False)\n",
        "\n",
        "    x = xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n",
        "                       skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n",
        "                       depth_activation=False)\n",
        "    x = xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n",
        "                       skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n",
        "                       depth_activation=True)\n",
        "    # end of feature extractor\n",
        "\n",
        "    # branching for Atrous Spatial Pyramid Pooling\n",
        "    # simple 1x1\n",
        "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n",
        "    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n",
        "    b0 = Activation('relu', name='aspp0_activation')(b0)\n",
        "\n",
        "    # rate = 6 (12)\n",
        "    b1 = SepConv_BN(x, 256, 'aspp1',\n",
        "                    rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n",
        "    # rate = 12 (24)\n",
        "    b2 = SepConv_BN(x, 256, 'aspp2',\n",
        "                    rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n",
        "    # rate = 18 (36)\n",
        "    b3 = SepConv_BN(x, 256, 'aspp3',\n",
        "                    rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n",
        "\n",
        "    # Image Feature branch\n",
        "    out_shape = int(np.ceil(input_shape[0] / OS))\n",
        "    b4 = AveragePooling2D(pool_size=(out_shape, out_shape))(x)\n",
        "    b4 = Conv2D(256, (1, 1), padding='same',\n",
        "                use_bias=False, name='image_pooling')(b4)\n",
        "    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n",
        "    b4 = Activation('relu')(b4)\n",
        "    b4 = BilinearUpsampling((out_shape, out_shape))(b4)\n",
        "\n",
        "    # concatenate ASPP branches & project\n",
        "    x = Concatenate()([b4, b0, b1, b2, b3])\n",
        "    x = Conv2D(256, (1, 1), padding='same',\n",
        "               use_bias=False, name='concat_projection')(x)\n",
        "    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    # DeepLab v.3+ decoder\n",
        "\n",
        "    # Feature projection\n",
        "    # x4 (x2) block\n",
        "    x = BilinearUpsampling(output_size=(int(np.ceil(input_shape[0] / 4)),\n",
        "                                        int(np.ceil(input_shape[1] / 4))))(x)\n",
        "    dec_skip1 = Conv2D(48, (1, 1), padding='same',\n",
        "                       use_bias=False, name='feature_projection0')(skip1)\n",
        "    dec_skip1 = BatchNormalization(\n",
        "        name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n",
        "    dec_skip1 = Activation('relu')(dec_skip1)\n",
        "    x = Concatenate()([x, dec_skip1])\n",
        "    x = SepConv_BN(x, 256, 'decoder_conv0',\n",
        "                   depth_activation=True, epsilon=1e-5)\n",
        "    x = SepConv_BN(x, 256, 'decoder_conv1',\n",
        "                   depth_activation=True, epsilon=1e-5)\n",
        "\n",
        "    # you can use it with arbitary number of classes\n",
        "    if classes == 21:\n",
        "        last_layer_name = 'logits_semantic'\n",
        "    else:\n",
        "        last_layer_name = 'custom_logits_semantic'\n",
        "\n",
        "    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n",
        "    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    model = Model(inputs, x, name='deeplabv3+')\n",
        "\n",
        "    # load weights\n",
        "\n",
        "    if weights == 'pascal_voc':\n",
        "        weights_path = get_file('deeplabv3_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                TF_WEIGHTS_PATH,\n",
        "                                cache_subdir='models')\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
        "    # Returns\n",
        "        Input array scaled to [-1.,1.]\n",
        "    \"\"\"\n",
        "    return imagenet_utils.preprocess_input(x, mode='tf')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}